# 用于Bot的深度学习技术及其面临的难题

> [深度 | Google Brain研究员详解聊天机器人：面临的深度学习技术问题以及基于TensorFlow的开发实践](http://www.10tiao.com/html/162/201607/2650716717/1.html)

## 模型分类

- 基于检索式模型 vs 生成式模型

    基于检索式模型（更简单）使用了预定义回复库和某种启发式方法来根据输入和语境做出合适的回复。这种启发式方法可以像基于规则的表达式匹配一样简单，也可以像机器学习分类器集一样复杂。这些系统不会产生任何新文本，他们只是从固定的集合中挑选一种回复而已。

    生成式模型（更困难）不依赖于预定义回复库。他们从零开始生成新回复。生成式模型通常基于机器翻译技术，但区别于语言翻译，我们把一个输入「翻译」成一个输出「回复」。

- 长对话 vs 短对话
 
    对话越长，就越难使它自动化。一方面，短文本对话（更简单）的目标是单独回复一个简单的输入。例如，你可能收到一个用户的特定问题并回复合适的答案。而长对话（更困难）要求你经历多个转折并需要记录说过什么话。客户支持类对话通常是包含多个问题的长对话流。

- 开域(open domain) vs 闭域(closeddomain)

    在开域（更困难）环境中，用户可以进行任何对话。不需要明确定义的目标或意图。像Twitter 和 Reddit 这种社交媒体网站上的对话通常是开域的——它们可以是任何主题。话题的无限数量和用于产生合理回复的一定量的知识使开域成为了一个艰难的问题。

    在闭域（更简单）设定中，因为系统试图达成一个非常明确的目标，可能输入和输出的空间会有所限制。例如客户技术支持或购物助手就属于闭域的范畴。这些系统不需要能谈论政治，它们只需要尽可能高效地完成它们特定的任务。当然，用户仍然可以进行任何他们想要的对话，但是这样的系统不需要能处理所有情况，并且用户也不期望它能处理。

## 普遍难题

- 整合语境

    为了生成明智的回复，系统可能需要整合语言语境（linguistic context）和物理语境（physical context）。在长对话中，人们记录已经被说过的话和已经交换过的信息。这是结合语言语境的例子。最普遍的方法是将对话嵌入一个向量中，但在长对话上进行这样的操作是很有挑战性的。「使用生成式分层神经网络模型构建端到端对话系统」和「神经网络对话模型的注意与意图」两个实验中都选择了这个研究方向。此外还可能需要整合其它类型的语境数据，例如日期/时间、位置或用户信息。

- 一致人格

    当生成回复时，对于语义相同的输入，代理应该生成相同的回答。例如，你想在「你多大了？」和「你的年龄是多少？」上得到同样的回答。这听起来很简单，但是将固定的知识或者「人格」整合进模型是非常困难的研究难题。许多系统学习如何生成语义合理的回复，但是它们没有被训练如何生成语义上一致的回复。这一般是因为它们是基于多个不同用户的数据训练的。「基于个人的神经对话模型」这样的模型是明确的对人格建模的方向上的第一步。

- 模型评估

    评估一个对话代理的理想方式是衡量它是否完成了它的任务，例如，在给定对话中解决客户支持问题。但是获取这样的标签成本高昂，因为它们要求人类的判断和评估。某些时候并不存在明确定义的目标，比如开域模型中的情况。通常像 BLEU 这样被用于机器翻译且是基于文本匹配的标准并不能胜任，因为智能的回复可以包括完全不同的单词或短语。实际上，在 How NOT To Evaluate Your Dialogue System: An Empirical Study of UnsupervisedEvaluation Metrics for Dialogue Response Generation 中，研究者发现没有一个通用的度量能真正与人类判断一一对应。

- 意图和多样性

    生成式系统的普遍问题是它们往往能生成像「太好了！」或「我不知道」这样的能适用于许多输入情况的普遍回复。谷歌的智能回复（Smart Reply ）早期版本常常用「我爱你」回复一切。一定程度上这是系统根据数据和实际训练目标/算法训练的结果。然而，人类通常使用针对输入的回复并带有意图。因为生成系统（特别是开域系统）是不被训练成有特定意图的，所以它们缺乏这种多样性。

## 实际工作情况

一个基于检索式开域系统显然是不可能实现的，因为你不能人工制作出足够的回复来覆盖所有情况。生成式开域系统几乎是人工通用智能（AGI: Artificial General Intelligence），因为它需要处理所有可能的场景。

在一般的话题上，它们还远不能实现如人类水平的沟通和语境理解能力；但在购物助手等狭窄领域的的应用中，训练有素的聊天机器人完全可以取代人类来协助和提升消费者的购物体验。

## 参阅

>Neural Responding Machine for Short-Text Conversation (2015-03)

>A Neural Conversational Model (2015-06)

>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses (2015-06)

>The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems (2015-06)

>Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models (2015-07)

>A Diversity-Promoting Objective Function for Neural Conversation Models (2015-10)

>Attention with Intention for a Neural Network Conversation Model (2015-10)

>Improved Deep Learning Baselines for Ubuntu Corpus Dialogs (2015-10)

>A Survey of Available Corpora for Building Data-Driven Dialogue Systems (2015-12)

>Incorporating Copying Mechanism in Sequence-to-Sequence Learning (2016-03)

>A Persona-Based Neural Conversation Model (2016-03)

>How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised     Evaluation Metrics for Dialogue Response Generation (2016-03)
